{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from openai import AssistantEventHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key from the environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Initialize the OpenAI client with your API key\n",
    "client = OpenAI(api_key=openai.api_key)\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set!\")\n",
    "openai.api_key = api_key\n",
    "client = OpenAI(api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_or_create_assistant(client, name, instructions, model):\n",
    "    # Fetch the list of existing assistants (no await needed)\n",
    "    assistants = client.beta.assistants.list()\n",
    "    \n",
    "    # Search for an assistant by name\n",
    "    for assistant in assistants:\n",
    "        if assistant.name == name:  # Use dot notation instead of subscript\n",
    "            print(f\"[INFO] Using existing assistant: {assistant.id}\")\n",
    "            return assistant\n",
    "    \n",
    "    # Create a new assistant if not found\n",
    "    print(\"[INFO] Creating a new assistant...\")\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=name,\n",
    "        instructions=instructions,\n",
    "        model=model,\n",
    "        tools=[{\"type\": \"file_search\"}]\n",
    "    )\n",
    "    print(f\"[INFO] New assistant created with ID: {assistant['id']}\")\n",
    "    return assistant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_or_create_vector_store(client, name, file_path):\n",
    "    # Fetch the list of existing vector stores (no await needed for list)\n",
    "    vector_stores = client.beta.vector_stores.list()\n",
    "    \n",
    "    # Iterate through existing vector stores\n",
    "    for store in vector_stores:\n",
    "        if store.name == name:  # Compare store.name with the provided name\n",
    "            print(f\"[INFO] Using existing vector store: {store.id}\")\n",
    "            return store.id  # Return the ID of the matched vector store\n",
    "    \n",
    "    # Create a new vector store if not found\n",
    "    print(\"[INFO] Creating a new vector store...\")\n",
    "    vector_store = await client.beta.vector_stores.create(name=name)\n",
    "    \n",
    "    # Upload files to the new vector store\n",
    "    file_streams = [open(file_path, \"rb\")]\n",
    "    file_batch = await client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "        vector_store_id=vector_store.id, files=file_streams\n",
    "    )\n",
    "    print(f\"[INFO] Vector store created with ID: {vector_store.id}\")\n",
    "    print(f\"[INFO] File batch status: {file_batch.status}\")\n",
    "    return vector_store.id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def update_assistant_with_knowledge_base(client, assistant_id, vector_store_id):\n",
    "    print(f\"[DEBUG] Linking vector store {vector_store_id} to assistant {assistant_id}...\")  # Add debug log\n",
    "    client.beta.assistants.update(\n",
    "        assistant_id=assistant_id,\n",
    "        tool_resources={\n",
    "            \"file_search\": {\"vector_store_ids\": [vector_store_id]}\n",
    "        }\n",
    "    )\n",
    "    print(f\"[INFO] Assistant {assistant_id} linked to vector store {vector_store_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process variables\n",
    "async def process_variables(df, client, assistant_id, thread_id):\n",
    "    for _, row in df.iterrows():\n",
    "        variable_name = row[\"Variable / Field Name\"]\n",
    "        module = row[\"Form Name\"]\n",
    "        title = row[\"Field Label\"]\n",
    "        description = row.get(\"Description\", \"\")\n",
    "        var_type = row.get(\"Field Type\", \"\")\n",
    "        encodings = row.get(\"Choices, Calculations, OR Slider Labels\", \"\")\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are a HEAL CDE identification assistant. Use the HEAL CDE knowledge base to analyze the following variable and determine if it matches any HEAL CDE. Provide a detailed explanation based on the HEAL CDE knowledge base.\n",
    "        - **Variable Name**: {variable_name}\n",
    "        - **Module**: {module}\n",
    "        - **Title**: {title}\n",
    "        - **Description**: {description}\n",
    "        - **Type**: {var_type}\n",
    "        - **Encodings**: {encodings}\n",
    "        \n",
    "        Respond based on the HEAL CDE knowledge base.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Send message to the assistant\n",
    "            client.beta.threads.messages.create(\n",
    "                thread_id=thread_id,\n",
    "                role=\"user\",\n",
    "                content=prompt\n",
    "            )\n",
    "            print(f\"[DEBUG] Successfully sent message for variable: {variable_name}\")\n",
    "\n",
    "            # Fetch the latest messages in the thread\n",
    "            thread_messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "            latest_message = None\n",
    "            for message in thread_messages:\n",
    "                latest_message = message  # Iterate to get the most recent message\n",
    "\n",
    "            if latest_message:\n",
    "                print(f\"[DEBUG] Assistant's response for {variable_name}: {latest_message.content}\")\n",
    "            else:\n",
    "                print(f\"[ERROR] No response received for variable '{variable_name}'\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to process variable '{variable_name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event handler class\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nassistant > {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using existing assistant: asst_1323thTbBBESBJYw3JlOTiiP\n",
      "[INFO] Using existing vector store: vs_22m2znc8T2bqfwkup3qKKCWG\n",
      "[DEBUG] Linking vector store vs_22m2znc8T2bqfwkup3qKKCWG to assistant asst_1323thTbBBESBJYw3JlOTiiP...\n",
      "[INFO] Assistant asst_1323thTbBBESBJYw3JlOTiiP linked to vector store vs_22m2znc8T2bqfwkup3qKKCWG\n",
      "Thread created with ID: thread_hxjJEtosfBVPkPWrR4SY71E1\n",
      "[DEBUG] File search test query response: [TextContentBlock(text=Text(annotations=[], value=\"Find any information about the variable 'age' in the HEAL CDE knowledge base.\"), type='text')]\n",
      "[INFO] Processing variables...\n",
      "[DEBUG] Successfully sent message for variable: exclusion_total\n",
      "[DEBUG] Assistant's response for exclusion_total: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: nrs\n",
      "[DEBUG] Assistant's response for nrs: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: nrs_total\n",
      "[DEBUG] Assistant's response for nrs_total: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: dob\n",
      "[DEBUG] Assistant's response for dob: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: age\n",
      "[DEBUG] Assistant's response for age: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: sexatbirth\n",
      "[DEBUG] Assistant's response for sexatbirth: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: gender_id\n",
      "[DEBUG] Assistant's response for gender_id: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: specify_gender\n",
      "[DEBUG] Assistant's response for specify_gender: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: ethnicity\n",
      "[DEBUG] Assistant's response for ethnicity: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[INFO] Finished processing variables.\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Main function\n",
    "async def main():\n",
    "    client = OpenAI(api_key=openai.api_key)\n",
    "    \n",
    "    # Define paths and names\n",
    "    vector_store_name = \"All HEAL CDEs KB\"\n",
    "    assistant_name = \"CDE-detective\"\n",
    "    knowledge_base_file = r\"C:\\Users\\lmaefos\\Code Stuffs\\CDE_detective\\CDE_ID_detective_revamp\\KnowledgeBase\\All_HEALPAINCDEsDD_flattened.json\"\n",
    "    data_dictionary_path = r\"C:\\Users\\lmaefos\\Code Stuffs\\CDE_detective\\CDE_ID_detective_revamp\\in\\SAMPLE_HDP00980_iHOPEAim1_DataDictionary_2024-12-13_enhanced.xlsx\"\n",
    "\n",
    "    # Check file paths\n",
    "    if not os.path.exists(knowledge_base_file):\n",
    "        print(f\"[ERROR] Knowledge base file not found: {knowledge_base_file}\")\n",
    "        return\n",
    "    if not os.path.exists(data_dictionary_path):\n",
    "        print(f\"[ERROR] Data dictionary file not found: {data_dictionary_path}\")\n",
    "        return\n",
    "\n",
    "    # Load data dictionary\n",
    "    try:\n",
    "        df = pd.read_excel(data_dictionary_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load data dictionary: {e}\")\n",
    "        return\n",
    "\n",
    "    # Create or get assistant and vector store\n",
    "    assistant = await get_or_create_assistant(\n",
    "        client, \n",
    "        assistant_name, \n",
    "        \"You are a HEAL CDE identification assistant. Use the provided knowledge base to analyze variables and determine if they match any HEAL CDE.\",\n",
    "        \"gpt-4o\"\n",
    "    )\n",
    "    vector_store_id = await get_or_create_vector_store(client, vector_store_name, knowledge_base_file)\n",
    "    \n",
    "    # Link assistant to vector store\n",
    "    try:\n",
    "        await update_assistant_with_knowledge_base(client, assistant.id, vector_store_id)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to link vector store: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Create a new thread\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Analyze variables from the data dictionary to determine HEAL CDE matches.\"\n",
    "            }\n",
    "        ],\n",
    "        tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store_id]}}\n",
    "    )\n",
    "\n",
    "    # Get the thread ID\n",
    "    thread_id = thread.id\n",
    "    print(f\"Thread created with ID: {thread_id}\")\n",
    "\n",
    "    # Test query to check file search functionality\n",
    "    try:\n",
    "        response = client.beta.threads.messages.create(\n",
    "            thread_id=thread_id,\n",
    "            role=\"user\",\n",
    "            content=\"Find any information about the variable 'age' in the HEAL CDE knowledge base.\"\n",
    "        )\n",
    "        print(f\"[DEBUG] File search test query response: {response.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to perform file search test query: {e}\")\n",
    "        return\n",
    "\n",
    "    # Process variables\n",
    "    print(\"[INFO] Processing variables...\")\n",
    "    try:\n",
    "        await process_variables(df, client, assistant.id, thread_id)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to process variables: {e}\")\n",
    "        return\n",
    "    print(\"[INFO] Finished processing variables.\")\n",
    "\n",
    "# Run the script\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'thread_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[232], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m thread_messages:\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] Message Role: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;241m.\u001b[39mrole\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Content: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m inspect_thread(client, \u001b[43mthread_id\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'thread_id' is not defined"
     ]
    }
   ],
   "source": [
    "async def simple_test(client):\n",
    "    # Create a thread with detailed system instructions\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": (\n",
    "                    \"You are an AI assistant. Your goal is to answer user questions clearly, concisely, \"\n",
    "                    \"and accurately. If the user asks 'What is the capital of France?', your response should be 'The capital of France is Paris.'\"\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    thread_id = thread.id\n",
    "    print(f\"Thread created with ID: {thread_id}\")\n",
    "\n",
    "    # Send a simple test query\n",
    "    try:\n",
    "        response = client.beta.threads.messages.create(\n",
    "            thread_id=thread_id,\n",
    "            role=\"user\",\n",
    "            content=\"What is the capital of France?\"\n",
    "        )\n",
    "        print(f\"[DEBUG] Assistant's response: {response.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to get response: {e}\")\n",
    "\n",
    "\n",
    "async def inspect_thread(client, thread_id):\n",
    "    thread_messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    for message in thread_messages:\n",
    "        print(f\"[DEBUG] Message Role: {message.role}, Content: {message.content}\")\n",
    "\n",
    "await inspect_thread(client, thread_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread created with ID: thread_a6DrAlbvO9osstf93gE4AL1i\n",
      "[DEBUG] Assistant's response: [TextContentBlock(text=Text(annotations=[], value='What is the capital of France?'), type='text')]\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    client = OpenAI(api_key=openai.api_key)\n",
    "\n",
    "    # Run the simple test to validate responses\n",
    "    await simple_test(client)\n",
    "\n",
    "# Run the script\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "import asyncio\n",
    "import configparser\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# openai: The OpenAI SDK to interact with their APIs.\n",
    "# json: For working with JSON data.\n",
    "# os: Access environment variables and file paths.\n",
    "# asyncio: Enables asynchronous operations for better performance.\n",
    "# configparser: Reads configuration files like config.ini.\n",
    "# OpenAI: A specific OpenAI class for client interactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key from the environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Initialize the OpenAI client with your API key\n",
    "client = OpenAI(api_key=openai.api_key)\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set!\")\n",
    "openai.api_key = api_key\n",
    "client = OpenAI(api_key=openai.api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an assistant named \"CDE-detective\" with specific instructions for identifying HEAL CDE variables.\n",
    "assistant = client.beta.assistants.create(\n",
    "name=\"CDE-detective\",\n",
    "instructions=\"You are a helpful HEAl CDE Identification assistant to see if a variable is a HEAL CDE based on the files provided to you. The goal is to determine whether each name, which represents a variable, matches a HEAL CDE variable from a pre-defined list of HEAL CDE variables stored in your knowledge base.\",\n",
    "model=\"gpt-4o\",\n",
    "tools=[{\"type\": \"file_search\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector store\n",
    "vector_store = client.beta.vector_stores.create(name=\"All HEAL CDEs KB\")\n",
    "\n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [r\"C:\\Users\\lmaefos\\Code Stuffs\\CDE_detective\\CDE_ID_detective_revamp\\KnowledgeBase\\All_HEALPAINCDEsDD_flattened.json\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "\n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the Assistant to Use the Vector Store\n",
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=assistant.id,\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")\n",
    "print(f\"[DEBUG] Assistant updated with tool resources: {assistant.tool_resources}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the user provided file to OpenAI\n",
    "message_file = client.files.create(\n",
    "file=open(r\"C:\\Users\\lmaefos\\Code Stuffs\\CDE_detective\\CDE_ID_detective_revamp\\in\\SAMPLE_DataDictionary_ForTesting.json\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "messages=[\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Analyze the contents of each name nested under its respective module in the provided JSON file. The goal is to determine whether each name, which represents a variable, matches a HEAL CDE variable from a pre-defined list of HEAL CDE variables stored in your knowledge base.\",\n",
    "    # Attach the new file to the message.\n",
    "    \"attachments\": [\n",
    "      { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "    ],\n",
    "  }\n",
    "]\n",
    ")\n",
    "\n",
    "# The thread now has a vector store with that file in its tool resources.\n",
    "print(thread.tool_resources.file_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data dictionary (CSV or Excel)\n",
    "file_path = r\"C:\\Users\\lmaefos\\Code Stuffs\\CDE_detective\\CDE_ID_detective_revamp\\in\\SAMPLE_HDP00980_iHOPEAim1_DataDictionary_2024-12-13_enhanced.xlsx\"  # Change to .xlsx if necessary\n",
    "df = pd.read_excel(file_path)  # Or use pd.read_excel(file_path)\n",
    "\n",
    "# Define column mappings (customize for your data dictionary)\n",
    "column_mappings = {\n",
    "    \"variable\": \"Variable / Field Name\",         # Replace \"name\" with your actual column name for variables\n",
    "    \"module\": \"Form Name\",\n",
    "    \"heal_crf_match\": \"Matched HEAL Core CRF\",\n",
    "    \"title\": \"Field Label\",\n",
    "    \"description\": \"\",\n",
    "    \"type\": \"Field Type\",\n",
    "    \"encodings\": \"Choices, Calculations, OR Slider Labels\",\n",
    "}\n",
    "\n",
    "# Validate that all columns exist in the DataFrame\n",
    "optional_columns = [\"description\", \"heal_crf_match\", \"type\", \"encodings\"]\n",
    "\n",
    "for key, col in column_mappings.items():\n",
    "    if col not in df.columns and key not in optional_columns:\n",
    "        raise ValueError(f\"Column '{col}' for '{key}' not found in the file.\")\n",
    "    elif col not in df.columns:\n",
    "        print(f\"Warning: Optional column '{col}' for '{key}' is missing. Defaulting to blank values.\")\n",
    "        df[col] = \"\"  # Create an empty column with blank values for optional fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_variables(df, client, assistant_id, thread_id):\n",
    "    for _, row in df.iterrows():\n",
    "        variable_name = row[column_mappings[\"variable\"]]\n",
    "        module = row[column_mappings[\"module\"]]\n",
    "        title = row[column_mappings[\"title\"]]\n",
    "        description = row[column_mappings[\"description\"]]\n",
    "        var_type = row[column_mappings[\"type\"]]\n",
    "        encodings = row[column_mappings[\"encodings\"]]\n",
    "\n",
    "        # Construct the prompt\n",
    "        prompt = f\"\"\"\n",
    "        Analyze the following variable:\n",
    "        - **Variable Name**: {variable_name}\n",
    "        - **Module**: {module}\n",
    "        - **Title**: {title}\n",
    "        - **Description**: {description}\n",
    "        - **Type**: {var_type}\n",
    "        - **Encodings**: {encodings}\n",
    "        \n",
    "        Do not summarize or review the entire reference document. Instead, determine if this specific variable matches any HEAL CDE and explain your reasoning.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Send message to the assistant\n",
    "        try:\n",
    "            await client.beta.threads.messages.create(\n",
    "                thread_id=thread_id,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            )\n",
    "            print(f\"[DEBUG] Successfully sent message for variable: {variable_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to process variable '{variable_name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Initialize the OpenAI client\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "    # Create the assistant\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=\"CDE-detective\",\n",
    "        instructions=\"You are a helpful HEAL CDE Identification assistant to see if a variable is a HEAL CDE based on the All_HEALPAINCDEsDD_flattened.json provided to you.\",\n",
    "        model=\"gpt-4o\",\n",
    "        tools=[{\"type\": \"file_search\"}]\n",
    "    )\n",
    "\n",
    "    # Create a new thread\n",
    "    thread = await client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"This thread will analyze variables from the data dictionary to determine HEAL CDE matches.\"\n",
    "            }\n",
    "        ],\n",
    "        assistant_id=assistant.id,\n",
    "    )\n",
    "\n",
    "    # Get the thread ID\n",
    "    thread_id = thread.id\n",
    "    print(f\"Thread created with ID: {thread_id}\")\n",
    "\n",
    "    # Pass the DataFrame to the processing function\n",
    "    print(\"[DEBUG] Calling process_variables...\")\n",
    "    await process_variables(df, client, assistant.id, thread_id=thread_id)\n",
    "    print(\"[DEBUG] Finished processing variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Assistant Events\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler, OpenAI\n",
    "\n",
    "client = OpenAI(api_key='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')\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "  @override\n",
    "  def on_text_created(self, text) -> None:\n",
    "      print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "  @override\n",
    "  def on_tool_call_created(self, tool_call):\n",
    "      print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "  @override\n",
    "  def on_message_done(self, message) -> None:\n",
    "    try:\n",
    "        message_content = message.content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(\n",
    "                annotation.text, f\"[{index}]\"\n",
    "            )\n",
    "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "                cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "        print(message_content.value)\n",
    "        print(\"\\n\".join(citations))\n",
    "    except AttributeError as e:\n",
    "        print(f\"Error processing message: {e}\")\n",
    "\n",
    "# Then, we use the stream SDK helper\n",
    "# with the EventHandler class to create the Run\n",
    "# and stream the response.\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Analyze the variable and its description to determine whether it matches a HEAL CDE variable from the HEAL CDE variables stored in your knowledge base.\",\n",
    "  event_handler=EventHandler(),\n",
    ") as stream:\n",
    "  stream.until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an asynchronous function to process a variable using OpenAI's chat completion\n",
    "async def extract_variable_metadata(variable_name, module_name, file_id):\n",
    "    instructions = \"\"\"\n",
    "    Objective: Process the raw responses from the output of the HEAL CDE Detective to produce a structured JSON format that aligns with the HEAL Core Common Data Elements (CDE) categorization.\n",
    "\n",
    "    Response Format:\n",
    "    For each variable entry, provide the following metadata in a flat JSON format:\n",
    "    {\n",
    "      \"variable_name\": \"<original variable name from the input file>\",\n",
    "      \"module_name\": \"<original module name from the input file>\",\n",
    "      \"Matched_HEAL_Core_CRF\": \"<HEAL_CRF_match name from input file>\", \n",
    "      \"standards_mapping_type\": \"<your chosen identification of whether or not this is a CDE match>\",\n",
    "      \"heal_cde_name\": \"<best match for HEAL CDE from the reference All_HEALPAINCDEsDD_flattened.json file>\",\n",
    "      \"variable_cde_name\": \"<the variable name as listed in the reference All_HEALPAINCDEsDD_flattened.json file for the respected HEAL CDE match>\"\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Variable Name: {variable_name}\n",
    "    Module Name: {module_name}\n",
    "\n",
    "    Using the provided file, generate the metadata for this variable based on the instructions above.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make the asynchronous API call\n",
    "    response = await openai.ChatCompletion.acreate(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": instructions},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"file\",\n",
    "                \"file_id\": file_id  # Use the actual file ID\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "\n",
    "    # Extract the response content\n",
    "    content = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    return content\n",
    "\n",
    "# Main async function to run the process\n",
    "async def main():\n",
    "    variable_name = \"tapstobaccoproductscl\"\n",
    "    module_name = \"tobacco_alcohol_prescription_medication_substance\"\n",
    "    file_id = \"file-Ev35xCQexzkLoLMN4RNAwR\"  # Replace with the actual file ID\n",
    "\n",
    "    # Call the extract function\n",
    "    metadata = await extract_variable_metadata(variable_name, module_name, file_id)\n",
    "    print(\"Extracted Metadata:\", metadata)\n",
    "\n",
    "# Run the main function\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARCHIVED BELOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import asyncio\n",
    "import os\n",
    "import pandas as pd  # For data handling, like reading from Excel\n",
    "from openai import AsyncOpenAI  # Asynchronous client from the new OpenAI SDK\n",
    "import json\n",
    "import configparser  # For reading configuration files\n",
    "import re\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Debugging: Print sections and keys\n",
    "print(f\"Config sections: {config.sections()}\")  # Should include 'OpenAI'\n",
    "if 'OpenAI' in config:\n",
    "    print(f\"Keys in OpenAI section: {config['OpenAI']}\")  # Should include 'api_key'\n",
    "\n",
    "# Retrieve the API key\n",
    "openai_api_key = config.get('OpenAI', 'api_key', fallback=None)\n",
    "print(f\"Retrieved API key: {openai_api_key}\")  # Debugging: Check the key value\n",
    "# Raise an error if the API key is missing\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"API key not found. Please set it in the 'config.ini' file under the [OpenAI] section.\")\n",
    "\n",
    "# Use the API key with OpenAI\n",
    "client = AsyncOpenAI(api_key=openai_api_key)\n",
    "print(\"Client initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve file paths and openai configs\n",
    "json_input_file = config['Files']['json_input_file']\n",
    "json_output_file = config['Files']['json_output_file']\n",
    "akshay_assistant_id = config['OpenAI']['akshay_assistant_id']\n",
    "variable_matching = config['Instructions']['variable_matching']\n",
    "akshay_vs_id = config['OpenAI']['akshay_vs_id']\n",
    "akshay_kb_file_id = config['OpenAI']['akshay_kb_file_id']\n",
    "akshay_kbdo_file_id = config['OpenAI']['akshay_kbdo_file_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Event Handler for debugging tool usage\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nassistant > Tool called: {tool_call.type}\")\n",
    "\n",
    "    def on_text_created(self, text):\n",
    "        print(f\"\\nassistant > {text}\")\n",
    "\n",
    "    def on_message_done(self, message):\n",
    "        print(f\"Assistant completed the message: {message.content[0].text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the assistant creation synchronously\n",
    "def create_assistant():\n",
    "    instructions = config.get(\"Instructions\", \"variable_matching\", fallback=None)\n",
    "    if not instructions:\n",
    "        raise ValueError(\"Instructions not found in config.ini.\")\n",
    "\n",
    "    # Run the coroutine to create the assistant\n",
    "    return asyncio.run(client.beta.assistants.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        instructions=instructions,\n",
    "        name=\"CDE ID Python\",\n",
    "        tools=[{\"type\": \"file_search\"}],\n",
    "        tool_resources={\n",
    "            \"file_search\": {\n",
    "                \"vector_store_ids\": [akshay_vs_id]\n",
    "            }\n",
    "        }\n",
    "    ))\n",
    "\n",
    "# Call the create_assistant function\n",
    "assistant = create_assistant()\n",
    "print(f\"Assistant created with tools: {assistant.tools}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_vector_stores():\n",
    "    vector_stores = []\n",
    "    async for store in client.beta.vector_stores.list():\n",
    "        vector_stores.append(store)\n",
    "    return vector_stores\n",
    "\n",
    "async def setup_vector_store():\n",
    "    try:\n",
    "        # Fetch the target vector store ID from the config\n",
    "        target_id = config['OpenAI']['akshay_vs_id']\n",
    "        print(f\"Target vector store ID: {target_id}\")  # Debugging\n",
    "\n",
    "        # Fetch the vector stores\n",
    "        vector_stores = await client.beta.vector_stores.list()\n",
    "\n",
    "        # Access the `data` attribute to get the list of VectorStore objects\n",
    "        vector_store_list = vector_stores.data  # This contains the actual VectorStore objects\n",
    "\n",
    "        # Iterate over the list of VectorStore objects\n",
    "        for store in vector_store_list:\n",
    "            print(f\"Checking vector store: {store.id}\")  # Debugging\n",
    "            if store.id == target_id:\n",
    "                print(f\"âœ… Using existing vector store: {store.id}\")\n",
    "                return store.id\n",
    "\n",
    "        # If we reach here, the target vector store wasn't found\n",
    "        raise ValueError(\"Vector store not found!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing vector store: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to send variable names to the assistant\n",
    "async def analyze_variables(client, assistant, modules, instructions):\n",
    "    \"\"\"\n",
    "    Asynchronously analyzes variable names by sending them to the assistant for matching with HEAL CDE variables.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for module_name, variable_names in modules.items():\n",
    "        module_results = []\n",
    "        for variable_name in variable_names:\n",
    "            print(f\"Processing variable '{variable_name}' in module '{module_name}'\")\n",
    "\n",
    "            prompt = f\"\"\"\n",
    "            Module Name: {module_name}\n",
    "            Variable Name: {variable_name}\n",
    "\n",
    "            {instructions}\n",
    "            \"\"\"\n",
    "\n",
    "            try:\n",
    "                # Step 1: Create a thread\n",
    "                thread = await client.beta.threads.create(\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "                )\n",
    "                print(f\"Thread created: {thread.id}\")\n",
    "\n",
    "                # Step 2: Poll the run until completion\n",
    "                await client.beta.threads.runs.create_and_poll(\n",
    "                    thread_id=thread.id,\n",
    "                    assistant_id=assistant.id\n",
    "                )\n",
    "                print(f\"Run completed for thread: {thread.id}\")\n",
    "\n",
    "                # Step 3: Retrieve the updated thread to access messages\n",
    "                updated_thread = await client.beta.threads.retrieve(thread.id)\n",
    "                if updated_thread.messages:\n",
    "                    # Get the last assistant message\n",
    "                    content = updated_thread.messages[-1].content.strip()\n",
    "                else:\n",
    "                    content = \"No response received\"\n",
    "\n",
    "                module_results.append({\n",
    "                    \"variable_name\": variable_name,\n",
    "                    \"response\": content\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing variable '{variable_name}' in module '{module_name}': {e}\")\n",
    "                module_results.append({\n",
    "                    \"variable_name\": variable_name,\n",
    "                    \"response\": f\"Error: {e}\"\n",
    "                })\n",
    "\n",
    "        results[module_name] = module_results\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    try:\n",
    "        # Load the JSON input file\n",
    "        json_input_file = config['Files']['json_input_file']\n",
    "        with open(json_input_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        print(\"JSON input file loaded successfully.\")\n",
    "\n",
    "        # Organize variables by module\n",
    "        modules = {module_name: [variable['name'] for variable in variables] for module_name, variables in data.items()}\n",
    "\n",
    "        # Define instructions\n",
    "        instructions = config.get(\"Instructions\", \"variable_matching\", fallback=None)\n",
    "        if not instructions:\n",
    "            raise ValueError(\"Instructions not found in config.ini.\")\n",
    "\n",
    "        # Setup vector store (awaiting setup)\n",
    "        vector_store_id = await setup_vector_store()  # This is fine\n",
    "        if not vector_store_id:\n",
    "            print(\"Failed to set up vector store. Exiting...\")\n",
    "            return\n",
    "\n",
    "        # Analyze variables asynchronously\n",
    "        results = await analyze_variables(client, assistant, modules, instructions)\n",
    "\n",
    "        # Save the results to a JSON file\n",
    "        json_output_file = config['Files']['json_output_file']\n",
    "        with open(json_output_file, 'w') as file:\n",
    "            json.dump(results, file, indent=4)\n",
    "        print(f\"Results saved to {json_output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main process: {e}\")\n",
    "\n",
    "# Run the async main function\n",
    "import asyncio\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and parse the JSON file\n",
    "with open(json_input_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Organize the variable names and \"Matched HEAL Core CRF\" by module\n",
    "modules = {}\n",
    "for module_name, variables in data.items():\n",
    "    modules[module_name] = [\n",
    "        {\n",
    "            'name': variable['name'],\n",
    "            'matched_crf': variable.get('Matched HEAL Core CRF', 'Not Available')  # Default to 'Not Available' if key doesn't exist\n",
    "        }\n",
    "        for variable in variables\n",
    "    ]\n",
    "\n",
    "# Display the loaded modules with variable names and matched CRF for debugging\n",
    "for module, variable_details in modules.items():\n",
    "    print(f\"Module: {module}\")\n",
    "    for detail in variable_details:\n",
    "        print(f\"  Variable: {detail['name']}, Matched HEAL Core CRF: {detail['matched_crf']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the JSON output from a file\n",
    "with open(json_output_file, 'r') as file:  # Replace with your actual file name\n",
    "    assistant_responses = json.load(file)\n",
    "\n",
    "# Debugging: Print the structure of the loaded data to understand the format\n",
    "print(assistant_responses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Extract relevant data from the JSON\n",
    "data = []\n",
    "\n",
    "for module_name, variables in assistant_responses.items():\n",
    "    for variable_entry in variables:\n",
    "        variable_name = variable_entry.get('variable_name', 'Unknown')\n",
    "        response = variable_entry.get('response', '')\n",
    "\n",
    "        # Use regex to extract fields from the response\n",
    "        match = re.search(r'\"standards_mapping_type\":\\s*\"([^\"]+)\"', response)\n",
    "        standards_mapping_type = match.group(1) if match else 'No Match'\n",
    "\n",
    "        match = re.search(r'\"heal_cde_name\":\\s*\"([^\"]+)\"', response)\n",
    "        heal_cde_name = match.group(1) if match else 'N/A'\n",
    "\n",
    "        match = re.search(r'\"variable_cde_name\":\\s*\"([^\"]+)\"', response)\n",
    "        variable_cde_name = match.group(1) if match else 'N/A'\n",
    "\n",
    "        # Append data to the list\n",
    "        data.append({\n",
    "            'Module Name': module_name,\n",
    "            'Variable Name': variable_name,\n",
    "            'Standards Mapping Type': standards_mapping_type,\n",
    "            'HEAL CDE Name': heal_cde_name,\n",
    "            'Variable CDE Name': variable_cde_name\n",
    "        })\n",
    "\n",
    "# Debugging: Print the first few rows of extracted data\n",
    "print(data[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Convert extracted data into a Pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Debugging: Display the DataFrame\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Export the DataFrame to an Excel file\n",
    "output_file = 'SAMPLE_DataDictionary_ForTesting_varmatch.xlsx'  # Name your file as you like\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Data successfully exported to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
