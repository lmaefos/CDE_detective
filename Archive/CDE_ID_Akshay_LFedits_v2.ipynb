{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define the path to your Excel file\n",
    "file_path = \"path_to_your_excel_file.xlsx\"  # Replace with the actual path to your file\n",
    "\n",
    "# Load the Excel file\n",
    "data_dict = pd.read_excel(file_path, sheet_name=0)  # Adjust the sheet name if needed\n",
    "\n",
    "# Define the required columns for the flattened JSON\n",
    "columns_to_extract = {\n",
    "    \"Variable Name\": \"Variable Name\",               # Column E\n",
    "    \"Extracted CRF Name\": \"Extracted CRF Name\",     # Column B\n",
    "    \"Matched HEAL Core CRF\": \"Matched HEAL Core CRF\",  # Column C\n",
    "    \"Match Confidence\": \"Match Confidence\",         # Column D\n",
    "    \"Short Description\": \"Short Description\",       # Column G\n",
    "    \"PV Description\": \"PV Description\",            # Column J\n",
    "    \"Data Type\": \"Data Type\"                        # Column K\n",
    "}\n",
    "\n",
    "# Extract and rename the required columns\n",
    "flattened_df = data_dict[list(columns_to_extract.values())].rename(columns=columns_to_extract)\n",
    "\n",
    "# Set the main entry key as \"Variable Name\"\n",
    "flattened_dict = flattened_df.set_index(\"Variable Name\").to_dict(orient=\"index\")\n",
    "\n",
    "# Save the flattened JSON file\n",
    "output_json_path = \"Flattened_DataDictionary_By_VariableName.json\"  # Adjust the output path if needed\n",
    "with open(output_json_path, \"w\") as file:\n",
    "    json.dump(flattened_dict, file, indent=4)\n",
    "\n",
    "print(f\"Flattened JSON file saved to: {output_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# talk to assistant via webapp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from openai import AssistantEventHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key from the environment variable\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set!\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_or_create_assistant(client, name, instructions):\n",
    "    # Fetch the list of existing assistants (no await needed)\n",
    "    assistants = client.beta.assistants.list()\n",
    "    \n",
    "    # Search for an assistant by name\n",
    "    for assistant in assistants:\n",
    "        if assistant.name == name:  # Use dot notation instead of subscript\n",
    "            print(f\"[INFO] Using existing assistant: {assistant.id}\")\n",
    "            return assistant\n",
    "    \n",
    "    # Create a new assistant if not found\n",
    "    print(\"[INFO] Creating a new assistant...\")\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=name,\n",
    "        instructions=instructions,\n",
    "        tools=[{\"type\": \"file_search\"}]\n",
    "    )\n",
    "    print(f\"[INFO] New assistant created with ID: {assistant['id']}\")\n",
    "    return assistant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using existing assistant: asst_LZR0DZ1lZNsHK7d15kdwndwd\n",
      "[INFO] Assistant ID: asst_LZR0DZ1lZNsHK7d15kdwndwd\n",
      "Thread created with ID: thread_IFmb4qtgfCd0kjNMMlEk1d1G\n",
      "[DEBUG] Thread message: user - [TextContentBlock(text=Text(annotations=[], value='What is the capital of France?'), type='text')]\n",
      "[DEBUG] Thread message: assistant - [TextContentBlock(text=Text(annotations=[], value='You are a helpful assistant. Answer user questions clearly and accurately.'), type='text')]\n",
      "[DEBUG] Assistant's response: [TextContentBlock(text=Text(annotations=[], value='Can you confirm the capital of France?'), type='text')]\n"
     ]
    }
   ],
   "source": [
    "# Main function to test thread creation and response\n",
    "async def main():\n",
    "    client = OpenAI(api_key=\"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\")  # Replace with your API key\n",
    "\n",
    "    # Create or get the assistant\n",
    "    assistant = await get_or_create_assistant(\n",
    "        client,\n",
    "        name=\"Test-Assistant\",\n",
    "        instructions=\"You are a helpful assistant. Answer user questions clearly and concisely.\"\n",
    "    )\n",
    "    print(f\"[INFO] Assistant ID: {assistant.id}\")\n",
    "    \n",
    "    # Create a new thread\n",
    "    try:\n",
    "        thread = client.beta.threads.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"You are a helpful assistant. Answer user questions clearly and accurately.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"What is the capital of France?\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        print(f\"Thread created with ID: {thread.id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to create thread: {e}\")\n",
    "        return\n",
    "\n",
    "    # Fetch all thread messages\n",
    "    try:\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        for message in messages:\n",
    "            print(f\"[DEBUG] Thread message: {message.role} - {message.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to fetch thread messages: {e}\")\n",
    "        return\n",
    "\n",
    "    # Send another message and fetch the assistant's response\n",
    "    try:\n",
    "        response = client.beta.threads.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=\"Can you confirm the capital of France?\"\n",
    "        )\n",
    "        print(f\"[DEBUG] Assistant's response: {response.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to send message or fetch response: {e}\")\n",
    "\n",
    "# Run the main function\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Assistant's response: [TextContentBlock(text=Text(annotations=[], value='What is the capital of France?'), type='text')]\n",
      "[DEBUG] Thread message: user - [TextContentBlock(text=Text(annotations=[], value='What is the capital of France?'), type='text')]\n",
      "[DEBUG] Thread message: user - [TextContentBlock(text=Text(annotations=[], value='What is the capital of France?'), type='text')]\n"
     ]
    }
   ],
   "source": [
    "response = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"What is the capital of France?\"\n",
    ")\n",
    "print(f\"[DEBUG] Assistant's response: {response.content}\")\n",
    "\n",
    "# Fetch and print all messages in the thread for troubleshooting\n",
    "thread_messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "for message in thread_messages:\n",
    "    print(f\"[DEBUG] Thread message: {message.role} - {message.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_or_create_vector_store(client, name, file_path):\n",
    "    # Fetch the list of existing vector stores (no await needed for list)\n",
    "    vector_stores = client.beta.vector_stores.list()\n",
    "    \n",
    "    # Iterate through existing vector stores\n",
    "    for store in vector_stores:\n",
    "        if store.name == name:  # Compare store.name with the provided name\n",
    "            print(f\"[INFO] Using existing vector store: {store.id}\")\n",
    "            return store.id  # Return the ID of the matched vector store\n",
    "    \n",
    "    # Create a new vector store if not found\n",
    "    print(\"[INFO] Creating a new vector store...\")\n",
    "    vector_store = await client.beta.vector_stores.create(name=name)\n",
    "    \n",
    "    # Upload files to the new vector store\n",
    "    file_streams = [open(file_path, \"rb\")]\n",
    "    file_batch = await client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "        vector_store_id=vector_store.id, files=file_streams\n",
    "    )\n",
    "    print(f\"[INFO] Vector store created with ID: {vector_store.id}\")\n",
    "    print(f\"[INFO] File batch status: {file_batch.status}\")\n",
    "    return vector_store.id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def update_assistant_with_knowledge_base(client, assistant_id, vector_store_id):\n",
    "    print(f\"[DEBUG] Linking vector store {vector_store_id} to assistant {assistant_id}...\")  # Add debug log\n",
    "    client.beta.assistants.update(\n",
    "        assistant_id=assistant_id,\n",
    "        tool_resources={\n",
    "            \"file_search\": {\"vector_store_ids\": [vector_store_id]}\n",
    "        }\n",
    "    )\n",
    "    print(f\"[INFO] Assistant {assistant_id} linked to vector store {vector_store_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process variables\n",
    "async def process_variables(df, client, assistant_id, thread_id):\n",
    "    for _, row in df.iterrows():\n",
    "        variable_name = row[\"Variable / Field Name\"]\n",
    "        module = row[\"Form Name\"]\n",
    "        title = row[\"Field Label\"]\n",
    "        description = row.get(\"Description\", \"\")\n",
    "        var_type = row.get(\"Field Type\", \"\")\n",
    "        encodings = row.get(\"Choices, Calculations, OR Slider Labels\", \"\")\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are a HEAL CDE identification assistant. Use the HEAL CDE knowledge base to analyze the following variable and determine if it matches any HEAL CDE. Provide a detailed explanation based on the HEAL CDE knowledge base.\n",
    "        - **Variable Name**: {variable_name}\n",
    "        - **Module**: {module}\n",
    "        - **Title**: {title}\n",
    "        - **Description**: {description}\n",
    "        - **Type**: {var_type}\n",
    "        - **Encodings**: {encodings}\n",
    "        \n",
    "        Respond based on the HEAL CDE knowledge base.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Send message to the assistant\n",
    "            client.beta.threads.messages.create(\n",
    "                thread_id=thread_id,\n",
    "                role=\"user\",\n",
    "                content=prompt\n",
    "            )\n",
    "            print(f\"[DEBUG] Successfully sent message for variable: {variable_name}\")\n",
    "\n",
    "            # Fetch the latest messages in the thread\n",
    "            thread_messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "            latest_message = None\n",
    "            for message in thread_messages:\n",
    "                latest_message = message  # Iterate to get the most recent message\n",
    "\n",
    "            if latest_message:\n",
    "                print(f\"[DEBUG] Assistant's response for {variable_name}: {latest_message.content}\")\n",
    "            else:\n",
    "                print(f\"[ERROR] No response received for variable '{variable_name}'\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to process variable '{variable_name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event handler class\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nassistant > {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using existing assistant: asst_LZR0DZ1lZNsHK7d15kdwndwd\n",
      "Thread created with ID: thread_5IYmz4Eu72JZKf6XBQ598V9D\n",
      "[DEBUG] Assistant's response: [TextContentBlock(text=Text(annotations=[], value='What is the capital of France?'), type='text')]\n"
     ]
    }
   ],
   "source": [
    "# Main function\n",
    "async def main():\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    # Create or get assistant\n",
    "    assistant = await get_or_create_assistant(\n",
    "        client,\n",
    "        \"Test-Assistant\",\n",
    "        \"You are a helpful assistant. Answer user questions clearly and concisely.\",\n",
    "        \"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    # Create a test thread\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the capital of France?\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Get the thread ID\n",
    "    thread_id = thread.id\n",
    "    print(f\"Thread created with ID: {thread_id}\")\n",
    "\n",
    "    # Fetch the assistant's response\n",
    "    try:\n",
    "        response = client.beta.threads.messages.create(\n",
    "            thread_id=thread_id,\n",
    "            role=\"user\",\n",
    "            content=\"What is the capital of France?\"\n",
    "        )\n",
    "        print(f\"[DEBUG] Assistant's response: {response.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to get response: {e}\")\n",
    "\n",
    "# Run the script\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using existing assistant: asst_1323thTbBBESBJYw3JlOTiiP\n",
      "[INFO] Using existing vector store: vs_22m2znc8T2bqfwkup3qKKCWG\n",
      "[DEBUG] Linking vector store vs_22m2znc8T2bqfwkup3qKKCWG to assistant asst_1323thTbBBESBJYw3JlOTiiP...\n",
      "[INFO] Assistant asst_1323thTbBBESBJYw3JlOTiiP linked to vector store vs_22m2znc8T2bqfwkup3qKKCWG\n",
      "Thread created with ID: thread_iI3hPJe40GCRyKqcuUxDgrHr\n",
      "[DEBUG] File search test query response: [TextContentBlock(text=Text(annotations=[], value=\"Find any information about the variable 'age' in the HEAL CDE knowledge base.\"), type='text')]\n",
      "[INFO] Processing variables...\n",
      "[DEBUG] Successfully sent message for variable: exclusion_total\n",
      "[DEBUG] Assistant's response for exclusion_total: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: nrs\n",
      "[DEBUG] Assistant's response for nrs: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: nrs_total\n",
      "[DEBUG] Assistant's response for nrs_total: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: dob\n",
      "[DEBUG] Assistant's response for dob: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: age\n",
      "[DEBUG] Assistant's response for age: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: sexatbirth\n",
      "[DEBUG] Assistant's response for sexatbirth: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: gender_id\n",
      "[DEBUG] Assistant's response for gender_id: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: specify_gender\n",
      "[DEBUG] Assistant's response for specify_gender: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[DEBUG] Successfully sent message for variable: ethnicity\n",
      "[DEBUG] Assistant's response for ethnicity: [TextContentBlock(text=Text(annotations=[], value='Analyze variables from the data dictionary to determine HEAL CDE matches.'), type='text')]\n",
      "[INFO] Finished processing variables.\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Main function\n",
    "async def main():\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    \n",
    "    # Define paths and names\n",
    "    vector_store_name = \"All HEAL CDEs KB\"\n",
    "    assistant_name = \"CDE-detective\"\n",
    "    knowledge_base_file = r\"C:\\Users\\lmaefos\\Code Stuffs\\CDE_detective\\CDE_ID_detective_revamp\\KnowledgeBase\\All_HEALPAINCDEsDD_flattened.json\"\n",
    "    data_dictionary_path = r\"C:\\Users\\lmaefos\\Code Stuffs\\CDE_detective\\CDE_ID_detective_revamp\\in\\SAMPLE_HDP00980_iHOPEAim1_DataDictionary_2024-12-13_enhanced.xlsx\"\n",
    "\n",
    "    # Check file paths\n",
    "    if not os.path.exists(knowledge_base_file):\n",
    "        print(f\"[ERROR] Knowledge base file not found: {knowledge_base_file}\")\n",
    "        return\n",
    "    if not os.path.exists(data_dictionary_path):\n",
    "        print(f\"[ERROR] Data dictionary file not found: {data_dictionary_path}\")\n",
    "        return\n",
    "\n",
    "    # Load data dictionary\n",
    "    try:\n",
    "        df = pd.read_excel(data_dictionary_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load data dictionary: {e}\")\n",
    "        return\n",
    "\n",
    "    # Create or get assistant and vector store\n",
    "    assistant = await get_or_create_assistant(\n",
    "        client, \n",
    "        assistant_name, \n",
    "        \"You are a HEAL CDE identification assistant. Use the provided knowledge base to analyze variables and determine if they match any HEAL CDE.\",\n",
    "        \"gpt-4o\"\n",
    "    )\n",
    "    vector_store_id = await get_or_create_vector_store(client, vector_store_name, knowledge_base_file)\n",
    "    \n",
    "    # Link assistant to vector store\n",
    "    try:\n",
    "        await update_assistant_with_knowledge_base(client, assistant.id, vector_store_id)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to link vector store: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Create a new thread\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Analyze variables from the data dictionary to determine HEAL CDE matches.\"\n",
    "            }\n",
    "        ],\n",
    "        tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store_id]}}\n",
    "    )\n",
    "\n",
    "    # Get the thread ID\n",
    "    thread_id = thread.id\n",
    "    print(f\"Thread created with ID: {thread_id}\")\n",
    "\n",
    "    # Test query to check file search functionality\n",
    "    try:\n",
    "        response = client.beta.threads.messages.create(\n",
    "            thread_id=thread_id,\n",
    "            role=\"user\",\n",
    "            content=\"Find any information about the variable 'age' in the HEAL CDE knowledge base.\"\n",
    "        )\n",
    "        print(f\"[DEBUG] File search test query response: {response.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to perform file search test query: {e}\")\n",
    "        return\n",
    "\n",
    "    # Process variables\n",
    "    print(\"[INFO] Processing variables...\")\n",
    "    try:\n",
    "        await process_variables(df, client, assistant.id, thread_id)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to process variables: {e}\")\n",
    "        return\n",
    "    print(\"[INFO] Finished processing variables.\")\n",
    "\n",
    "# Run the script\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
