{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import asyncio\n",
    "import os\n",
    "from openai import AsyncOpenAI  # Asynchronous client from the new OpenAI SDK\n",
    "import configparser  # For reading configuration files\n",
    "import json\n",
    "import re\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Debugging: Print sections and keys\n",
    "print(f\"Config sections: {config.sections()}\")  # Should include 'OpenAI'\n",
    "if 'OpenAI' in config:\n",
    "    print(f\"Keys in OpenAI section: {config['OpenAI']}\")  # Should include 'api_key'\n",
    "\n",
    "# Retrieve the API key\n",
    "openai_api_key = config.get('OpenAI', 'api_key', fallback=None)\n",
    "print(f\"Retrieved API key: {openai_api_key}\")  # Debugging: Check the key value\n",
    "\n",
    "# Raise an error if the API key is missing\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"API key not found. Please set it in the 'config.ini' file under the [OpenAI] section.\")\n",
    "\n",
    "# Use the API key with OpenAI\n",
    "client = AsyncOpenAI(api_key=openai_api_key)\n",
    "print(\"Client initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve file paths and openai configs\n",
    "json_input_file = config['Files']['json_input_file']\n",
    "json_output_file = config['Files']['json_output_file']\n",
    "akshay_assistant_id = config['OpenAI']['akshay_assistant_id']\n",
    "variable_matching = config['Instructions']['variable_matching']\n",
    "akshay_vs_id = config['OpenAI']['akshay_vs_id']\n",
    "akshay_kb_file_id = config['OpenAI']['akshay_kb_file_id']\n",
    "akshay_kbdo_file_id = config['OpenAI']['akshay_kbdo_file_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and parse the JSON file\n",
    "with open(json_input_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Organize the variable names by module\n",
    "modules = {}\n",
    "for module_name, variables in data.items():\n",
    "    modules[module_name] = [variable['name'] for variable in variables]\n",
    "\n",
    "# Display the loaded modules and variable names for debugging\n",
    "for module, variable_names in modules.items():\n",
    "    print(f\"Module: {module}, Variables: {variable_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the assistant\n",
    "instructions = config.get(\"Instructions\", \"variable_matching\", fallback=None)\n",
    "if not instructions:\n",
    "    raise ValueError(\"Instructions not found in config.ini.\")\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    instructions=instructions,\n",
    "    name=\"CDE ID Python\",\n",
    "    tools=[{\"type\": \"file_search\"}]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store reference files. These will be permanently accessible to the assistant.\n",
    "vector_store = client.beta.vector_stores.create(name=\"CDE Files\")\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\lmaefos\\Code Stuffs\\CDE_detective\\CDE_ID_detective_revamp\\KnowledgeBase\\All_HEALPAINCDEsDD_JSON.json\"\n",
    "]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=akshay_vs_id, files=file_streams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the async function to send variable names to the assistant\n",
    "async def analyze_variables(client, assistant, modules):\n",
    "    \"\"\"\n",
    "    Analyzes variable names by sending them to the assistant for matching with HEAL CDE variables.\n",
    "\n",
    "    Args:\n",
    "        client: The OpenAI client instance.\n",
    "        assistant: The assistant instance to process variables.\n",
    "        modules: A dictionary where keys are module names and values are lists of variable names.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with results for each module and variable.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for module_name, variable_names in modules.items():\n",
    "        module_results = []\n",
    "        for variable_name in variable_names:\n",
    "            # Construct a prompt for each variable\n",
    "            prompt = f\"\"\"\n",
    "            Module Name: {module_name}\n",
    "            Variable Name: {variable_name}\n",
    "\n",
    "            {instructions}\n",
    "            \"\"\"\n",
    "            # Call the assistant\n",
    "            response = await client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini-2024-07-18\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.5\n",
    "            )\n",
    "\n",
    "            # Parse the response content\n",
    "            content = response.choices[0].message.content.strip()\n",
    "            module_results.append({\n",
    "                \"variable_name\": variable_name,\n",
    "                \"response\": content\n",
    "            })\n",
    "\n",
    "        # Store results for the module\n",
    "        results[module_name] = module_results\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Load the JSON input file\n",
    "    json_input_file = config['Files']['json_input_file']\n",
    "    with open(json_input_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Organize variables by module\n",
    "    modules = {module_name: [variable['name'] for variable in variables] for module_name, variables in data.items()}\n",
    "\n",
    "    # Analyze variables with the assistant\n",
    "    results = await analyze_variables(client, assistant, modules)\n",
    "\n",
    "    # Save the results to a JSON file\n",
    "    json_output_file = config['Files']['json_output_file']\n",
    "    with open(json_output_file, 'w') as file:\n",
    "        json.dump(results, file, indent=4)\n",
    "\n",
    "    print(f\"Results saved to {json_output_file}\")\n",
    "\n",
    "# Run the async function\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# akshay original\n",
    "assistant = openai.Client().beta.assistants.create(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    instructions=\"\"\"Objective: Process the raw responses from the output of the HEAL CDE Detective to produce a structured JSON format that aligns with the HEAL Core Common Data Elements (CDE) categorization.\n",
    "\n",
    "                Response Format:\n",
    "                For each entry in the module, provide the following in a nested JSON format:\n",
    "                {\n",
    "                  \"module_name\": \"<module name>\",\n",
    "                  \"entries\": [\n",
    "                    {\n",
    "                      \"name\": \"<entry name>\",\n",
    "                      \"standards_mapping_type\": \"<CDE mapping type>\",\n",
    "                      \"cde_name\": \"<CDE name>\",\n",
    "                      \"variable_cde_name\": \"<variable name>\"\n",
    "                    },\n",
    "                    ...\n",
    "                  ]\n",
    "                }\n",
    "\n",
    "                Guidelines:\n",
    "                1. Parse Raw Responses: Extract and organize information from the raw response provided by the first assistant.\n",
    "                2. Determine Standards Mapping Type:\n",
    "                - HEAL CDE Match: When the entry matches a CDE directly.\n",
    "                - Potential HEAL CDE Match: When the entry partially matches a CDE or aligns with its context.\n",
    "                - No CDE match: When the entry does not correspond to any CDE.\n",
    "                3. Specify Standards Mapping Label: The CDE name derived from the All_HEALPAINCDEsDD_JSON.json file or indicate 'No CDE name'.\n",
    "                4. Specify Variable Name: Provide the matched variable name derived from the ALL_HEALPAINCDEsDD_JSON.json file or indicate 'No variable match'.\n",
    "\n",
    "                Example Output:\n",
    "                {\n",
    "                  \"module_name\": \"baseline_assessment\",\n",
    "                  \"entries\": [\n",
    "                    {\n",
    "                      \"name\": \"birth\",\n",
    "                      \"standards_mapping_type\": \"HEAL CDE Match\",\n",
    "                      \"cde_name\": \"Birth date\",\n",
    "                      \"variable_cde_name\":\"BRTHDTC\"\n",
    "                    },\n",
    "                    {\n",
    "                      \"name\": \"age_at_enrollment\",\n",
    "                      \"standards_mapping_type\": \"HEAL CDE Match\",\n",
    "                      \"cde_name\": \"Age\",\n",
    "                      \"variable_cde_name\":\"Age\"\n",
    "                    }\n",
    "                  ]\n",
    "                }\"\"\",\n",
    "    name=\"CDE ID Python\",\n",
    "    tools=[{\"type\": \"file_search\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store reference files. These will be permanently accessible to the assistant.\n",
    "vector_store = client.beta.vector_stores.create(name=\"CDE Files\")\n",
    "file_paths = [r\"C:\\Users\\lmaefos\\Code Stuffs\\CDE_detective\\CDE_ID_detective_revamp\\KnowledgeBase\\All_HEALPAINCDEsDD_JSON.json\", r\"C:\\Users\\lmaefos\\Code Stuffs\\CDE_detective\\CDE_ID_detective_revamp\\desiredoutcome.json\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the assistant to intake reference files.\n",
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Files that are going to be used in the message. See \"attachments\" in the block below.\n",
    "sample_output_file = client.files.create(\n",
    "    file=open(r\"C:\\Users\\lmaefos\\Code Stuffs\\CDE_detective\\CDE_ID_detective_revamp\\out\\HDP00125_DataDictionary_2023-08-22_2024-12-09_varmatch.json\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create message thread\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"Adjust the sample output provided according to the instructions to produce a file that looks like the desired outcome file.\n",
    "      The sample output is a json file that contains modules with information that you need to parse through.\n",
    "      I want you to determine whether each entry in the module matches with a CDE. The CDE list is found in the All_HEALPAINCDEsDD_JSON.\n",
    "      You should output text that is in the same format as the desired outcome, which is another json file. Here are the instructions:\n",
    "      Objective: Process the raw responses from the output of the HEAL CDE Detective to produce a structured JSON format that aligns with the HEAL Core Common Data Elements (CDE) categorization.\n",
    "\n",
    "        Response Format:\n",
    "        For each entry in the module, provide the following in a nested JSON format:\n",
    "        {\n",
    "          \"module_name\": \"<module name>\",\n",
    "          \"entries\": [\n",
    "            {\n",
    "              \"name\": \"<entry name>\",\n",
    "              \"standards_mapping_type\": \"<CDE mapping type>\",\n",
    "              \"cde_name\": \"<CDE name>\",\n",
    "              \"variable_cde_name\":\"<variable name>\"\n",
    "            },\n",
    "            ...\n",
    "          ]\n",
    "        }\n",
    "\n",
    "        Guidelines:\n",
    "                1. Parse Raw Responses: Extract and organize information from the raw response provided by the first assistant.\n",
    "                2. Determine Standards Mapping Type:\n",
    "                - HEAL CDE Match: When the entry matches a CDE directly.\n",
    "                - Potential HEAL CDE Match: When the entry partially matches a CDE or aligns with its context.\n",
    "                - No CDE match: When the entry does not correspond to any CDE.\n",
    "                3. Specify Standards Mapping Label: The CDE name derived from the All_HEALPAINCDEsDD_JSON.json file or indicate 'No CDE name'.\n",
    "                4. Specify Variable Name: Provide the matched variable name derived from the ALL_HEALPAINCDEsDD_JSON.json file or indicate 'No variable match'.\n",
    "\n",
    "                Example Output:\n",
    "                {\n",
    "                  \"module_name\": \"baseline_assessment\",\n",
    "                  \"entries\": [\n",
    "                    {\n",
    "                      \"name\": \"birth\",\n",
    "                      \"standards_mapping_type\": \"HEAL CDE Match\",\n",
    "                      \"cde_name\": \"Birth date\",\n",
    "                      \"variable_cde_name\":\"BRTHDTC\"\n",
    "                    },\n",
    "                    {\n",
    "                      \"name\": \"age_at_enrollment\",\n",
    "                      \"standards_mapping_type\": \"HEAL CDE Match\",\n",
    "                      \"cde_name\": \"Age\",\n",
    "                      \"variable_cde_name\":\"Age\"\n",
    "                    }\n",
    "                  ]\n",
    "                }\"\"\",\n",
    "      # Attach the new file to the message.\n",
    "      \"attachments\": [\n",
    "        { \"file_id\": sample_output_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute message thread. DO NOT CHANGE (for now)\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler, OpenAI\n",
    " \n",
    "client = OpenAI()\n",
    " \n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_message_done(self, message) -> None:\n",
    "        # print a citation to the file searched\n",
    "        message_content = message.content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(\n",
    "                annotation.text, f\"[{index}]\"\n",
    "            )\n",
    "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "                cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "        print(message_content.value)\n",
    "        print(\"\\n\".join(citations))\n",
    "\n",
    "\n",
    "# Then, we use the stream SDK helper\n",
    "# with the EventHandler class to create the Run\n",
    "# and stream the response.\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"Please parse through the whole sample output file.\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
