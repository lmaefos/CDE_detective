{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import asyncio\n",
    "import os\n",
    "import pandas as pd  # For data handling, like reading from Excel\n",
    "from openai import AsyncOpenAI  # Asynchronous client from the new OpenAI SDK\n",
    "import json\n",
    "import configparser  # For reading configuration files\n",
    "import re\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Retrieve file paths and column names from config\n",
    "input_file = config['Files']['input_file']\n",
    "input_worksheet = config['Files']['input_worksheet']\n",
    "crf_column = config['Columns']['crf_column']\n",
    "variable_column = config['Columns']['variable_column']\n",
    "description_column = config['Columns']['description_column']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI API key\n",
    "openai_api_key = config['OpenAI']['api_key']\n",
    "client = AsyncOpenAI(api_key=openai_api_key)# Retrieve OpenAI settings from the config file\n",
    "\n",
    "assistant_id = config['OpenAI']['assistant_id']\n",
    "assistant_id_0 = config['OpenAI']['assistant_id_0']\n",
    "crf_id_0 = config['Instructions']['crf_id_0']\n",
    "crf_id = config['Instructions']['crf_id']\n",
    "matching_instruction = config['Instructions']['matching_instruction']\n",
    "file_id = config['OpenAI']['file_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Data Dictionary:\n",
      "                                       Form Name Variable / Field Name  \\\n",
      "0  adolescent_sleep_wake_scale_short_form_aswssf               awsw_i1   \n",
      "1  adolescent_sleep_wake_scale_short_form_aswssf               awsw_i2   \n",
      "2  adolescent_sleep_wake_scale_short_form_aswssf                awsw_1   \n",
      "3  adolescent_sleep_wake_scale_short_form_aswssf               awsw_i3   \n",
      "4  adolescent_sleep_wake_scale_short_form_aswssf                awsw_2   \n",
      "\n",
      "                                         Field Label  \n",
      "0  Using the choices below, select how often the ...  \n",
      "1                      When its time to go to bed...  \n",
      "2  1. ...I want to stay up and do other things (f...  \n",
      "3                                      In general...  \n",
      "4          2. ...I am ready to go to bed at bedtime.  \n",
      "\n",
      "Grouped CRF Names with Descriptions and Variable Names:\n",
      "                                        CRF Name  \\\n",
      "0  adolescent_sleep_wake_scale_short_form_aswssf   \n",
      "1          brief_pain_inventory_short_form_bpisf   \n",
      "\n",
      "                                        Descriptions  \\\n",
      "0  Using the choices below, select how often the ...   \n",
      "1  Have you had pain today related to your pain c...   \n",
      "\n",
      "                                      Variable Names  \n",
      "0  awsw_i1, awsw_i2, awsw_1, awsw_i3, awsw_2, aws...  \n",
      "1  bpi_1, bpi_2, bpi_2a_m, bpi_2a_f, bpi_3, bpi_4...  \n"
     ]
    }
   ],
   "source": [
    "# Load the data dictionary from Excel file\n",
    "data_dict_df = pd.read_excel(input_file, sheet_name=input_worksheet)\n",
    "\n",
    "# Select only the relevant columns\n",
    "data_dict_df = data_dict_df[[crf_column, variable_column, description_column]]\n",
    "\n",
    "# Display the first few rows of the loaded data\n",
    "print(\"Loaded Data Dictionary:\")\n",
    "print(data_dict_df.head())\n",
    "\n",
    "# Group descriptions by each unique CRF\n",
    "# Concatenate all descriptions for each CRF into a single string\n",
    "grouped_descriptions_df = (\n",
    "    data_dict_df.groupby(crf_column)[description_column]\n",
    "    .apply(lambda x: ' '.join(x.dropna()))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Group variable names by each unique CRF\n",
    "# Concatenate all variable names for each CRF into a comma-separated string\n",
    "grouped_variables_df = (\n",
    "    data_dict_df.groupby(crf_column)[variable_column]\n",
    "    .apply(lambda x: ', '.join(x.dropna()))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge grouped descriptions and variable names on CRF Name\n",
    "grouped_crf_df = grouped_descriptions_df.merge(\n",
    "    grouped_variables_df, on=crf_column, how='left'\n",
    ")\n",
    "\n",
    "# Rename columns for clarity\n",
    "grouped_crf_df.columns = ['CRF Name', 'Descriptions', 'Variable Names']\n",
    "\n",
    "# Display the grouped DataFrame with descriptions and variables\n",
    "print(\"\\nGrouped CRF Names with Descriptions and Variable Names:\")\n",
    "print(grouped_crf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 0 in API call\n",
    "\n",
    "async def refine_crf_name_with_variables(client, crf_name, variable_names, descriptions):\n",
    "    \"\"\"\n",
    "    Calls OpenAI to refine/formulate a unique, concise CRF name \n",
    "    based on the original CRF name, variable names, and descriptions.\n",
    "    \"\"\"\n",
    "    prompt = f\"{crf_id_0}\\n\\nOriginal form name: {crf_name}\\n\\nVariable names: {variable_names}\\n\\nDescriptions: {descriptions}\"\n",
    "\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.5,\n",
    "        # optionally specify assistant ID if you want to directly target your step 0 assistant:\n",
    "        # assistant=assistant_id_0\n",
    "    )\n",
    "    content = response.choices[0].message.content.strip()\n",
    "    \n",
    "    # We expect a simple string — the refined CRF name (no complex parsing needed)\n",
    "    print(\"\\n--- Step 0 Response ---\\n\", content, \"\\n--- End of Step 0 Response ---\\n\")\n",
    "    return content\n",
    "\n",
    "async def run_step_0(client, grouped_crf_df):\n",
    "    tasks = []\n",
    "    for _, row in grouped_crf_df.iterrows():\n",
    "        crf_name = row[\"CRF Name\"]\n",
    "        variable_names = row[\"Variable Names\"]\n",
    "        descriptions = row[\"Descriptions\"]\n",
    "        task = refine_crf_name_with_variables(client, crf_name, variable_names, descriptions)\n",
    "        tasks.append(task)\n",
    "    \n",
    "    refined_names = await asyncio.gather(*tasks)\n",
    "    \n",
    "    # Handle any empty responses by falling back to original CRF Name\n",
    "    refined_names = [\n",
    "        name if name.strip() else grouped_crf_df.iloc[idx][\"CRF Name\"]\n",
    "        for idx, name in enumerate(refined_names)\n",
    "    ]\n",
    "    \n",
    "    # Add the refined names as a new column\n",
    "    grouped_crf_df[\"Refined CRF Name\"] = refined_names\n",
    "\n",
    "    print(\"\\nRefined CRF Names (Step 0) added to DataFrame:\")\n",
    "    print(grouped_crf_df[[\"CRF Name\", \"Refined CRF Name\"]].head())\n",
    "\n",
    "    return grouped_crf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 of 2 in API call\n",
    "\n",
    "def parse_extracted_crf_name(response_content):\n",
    "    \"\"\"\n",
    "    Parse the response to extract the full CRF name, including descriptors like \"Short Form\" or abbreviations in parentheses.\n",
    "    \"\"\"\n",
    "    # Debug: Print the full response content\n",
    "    print(\"\\n--- Full Response Content ---\\n\", response_content, \"\\n--- End of Response ---\\n\")\n",
    "\n",
    "    # Modify the regex to capture the entire CRF name, including phrases like \"Short Form\"\n",
    "    crf_name_pattern = r\"(?i)CRF name\\s*:\\s*([\\w\\s-]+(?:\\(.+?\\))?)\"\n",
    "    crf_match = re.search(crf_name_pattern, response_content)\n",
    "    matched_crf = re.sub(r'-\\s*Rationale$', '', crf_match.group(1).strip()) if crf_match else \"Unknown CRF\"\n",
    "\n",
    "    # Extract rationale if available\n",
    "    rationale_pattern = r\"(?i)Rationale\\s*:\\s*(.+)\"\n",
    "    rationale_match = re.search(rationale_pattern, response_content)\n",
    "    rationale = rationale_match.group(1).strip() if rationale_match else \"No rationale provided\"\n",
    "\n",
    "    return {\n",
    "        \"Extracted CRF Name\": matched_crf,\n",
    "        \"Rationale\": rationale,\n",
    "        \"Response\": response_content  # Full response for reference\n",
    "    }\n",
    "\n",
    "async def extract_crf_name(client, crf_name, descriptions):\n",
    "    prompt = f\"{crf_id}\\n\\nCRF Name: {crf_name}\\nDescriptions: {descriptions}\"\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    content = response.choices[0].message.content.strip()\n",
    "    return parse_extracted_crf_name(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 of 2 in API call\n",
    "\n",
    "def parse_heal_crf_match(response_content):\n",
    "    \"\"\"\n",
    "    Parse the response to extract a matched HEAL Core CRF name and confidence level.\n",
    "    This is used for Step 2.\n",
    "    \"\"\"\n",
    "    # Extract HEAL Core CRF match\n",
    "    crf_match = re.search(r\"(?i)HEAL Core CRF Match:\\s*(.+?)(?=\\s*-|$)\", response_content, re.DOTALL)\n",
    "    matched_crf = crf_match.group(1).strip() if crf_match else \"No CRF match\"\n",
    "\n",
    "    # Extract confidence level\n",
    "    confidence_match = re.search(r\"(?i)Confidence\\s*[Ll]evel:\\s*(High Confidence|Medium Confidence|Low Confidence|No Match)\", response_content)\n",
    "    confidence_level = confidence_match.group(1).strip() if confidence_match else \"No Confidence Score\"\n",
    "\n",
    "    return {\n",
    "        \"Matched CRF\": matched_crf,\n",
    "        \"Confidence\": confidence_level,\n",
    "        \"Response\": response_content  # Full response for reference\n",
    "    }\n",
    "\n",
    "# Async function to call OpenAI API with the new version syntax\n",
    "async def get_crf_match_from_openai(client, extracted_crf_name, descriptions):\n",
    "    prompt = f\"{matching_instruction}\\n\\nCRF Name: {extracted_crf_name}\\nDescriptions: {descriptions}\"\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    content = response.choices[0].message.content.strip()\n",
    "    return parse_heal_crf_match(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asynchronous function to process all CRFs concurrently\n",
    "async def analyze_crfs(client, crf_df):\n",
    "    # Step 0: Refine CRF Names\n",
    "    crf_df = await run_step_0(client, crf_df)\n",
    "\n",
    "    # Step 1: Extract CRF names using refined names\n",
    "    step1_tasks = []\n",
    "    for _, row in crf_df.iterrows():\n",
    "        refined_crf_name = row[\"Refined CRF Name\"]\n",
    "        descriptions = row[\"Descriptions\"]\n",
    "        task = extract_crf_name(client, refined_crf_name, descriptions)\n",
    "        step1_tasks.append(task)\n",
    "\n",
    "    extracted_names = await asyncio.gather(*step1_tasks)\n",
    "\n",
    "    # Step 2: Match extracted CRF names with HEAL Core CRFs\n",
    "    step2_tasks = []\n",
    "    for idx, extracted in enumerate(extracted_names):\n",
    "        extracted_crf_name = extracted[\"Extracted CRF Name\"]\n",
    "        descriptions = crf_df.iloc[idx][\"Descriptions\"]\n",
    "        task = get_crf_match_from_openai(client, extracted_crf_name, descriptions)\n",
    "        step2_tasks.append(task)\n",
    "\n",
    "    matches = await asyncio.gather(*step2_tasks)\n",
    "\n",
    "    # Format and return results as before\n",
    "    results = []\n",
    "    for idx, (extracted, match) in enumerate(zip(extracted_names, matches)):\n",
    "        original_crf_name = crf_df.iloc[idx][\"CRF Name\"]\n",
    "        results.append({\n",
    "            \"Original CRF Name\": original_crf_name,\n",
    "            \"Refined CRF Name\": crf_df.iloc[idx][\"Refined CRF Name\"],\n",
    "            \"Extracted CRF Name\": extracted[\"Extracted CRF Name\"],\n",
    "            \"Rationale\": extracted[\"Rationale\"],\n",
    "            \"Full Response (Extracted CRF)\": extracted[\"Response\"],\n",
    "            \"Matched HEAL Core CRF\": match.get(\"Matched CRF\", \"No Match\"),\n",
    "            \"Match Confidence\": match.get(\"Confidence\", \"No Confidence\"),\n",
    "            \"Match Full Response\": match.get(\"Response\")\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Data Dictionary:\n",
      "                                       Form Name Variable / Field Name  \\\n",
      "0  adolescent_sleep_wake_scale_short_form_aswssf               awsw_i1   \n",
      "1  adolescent_sleep_wake_scale_short_form_aswssf               awsw_i2   \n",
      "2  adolescent_sleep_wake_scale_short_form_aswssf                awsw_1   \n",
      "3  adolescent_sleep_wake_scale_short_form_aswssf               awsw_i3   \n",
      "4  adolescent_sleep_wake_scale_short_form_aswssf                awsw_2   \n",
      "\n",
      "                                         Field Label  \n",
      "0  Using the choices below, select how often the ...  \n",
      "1                      When its time to go to bed...  \n",
      "2  1. ...I want to stay up and do other things (f...  \n",
      "3                                      In general...  \n",
      "4          2. ...I am ready to go to bed at bedtime.  \n",
      "\n",
      "Grouped CRF Names with Descriptions and Variable Names:\n",
      "                                        CRF Name  \\\n",
      "0  adolescent_sleep_wake_scale_short_form_aswssf   \n",
      "1          brief_pain_inventory_short_form_bpisf   \n",
      "\n",
      "                                        Descriptions  \\\n",
      "0  Using the choices below, select how often the ...   \n",
      "1  Have you had pain today related to your pain c...   \n",
      "\n",
      "                                      Variable Names  \n",
      "0  awsw_i1, awsw_i2, awsw_1, awsw_i3, awsw_2, aws...  \n",
      "1  bpi_1, bpi_2, bpi_2a_m, bpi_2a_f, bpi_3, bpi_4...  \n",
      "\n",
      "--- Step 0 Response ---\n",
      " Brief Pain Inventory Short Form \n",
      "--- End of Step 0 Response ---\n",
      "\n",
      "\n",
      "--- Step 0 Response ---\n",
      " Adolescent Sleep-Wake Scale (ASWS) \n",
      "--- End of Step 0 Response ---\n",
      "\n",
      "\n",
      "Refined CRF Names (Step 0) added to DataFrame:\n",
      "                                        CRF Name  \\\n",
      "0  adolescent_sleep_wake_scale_short_form_aswssf   \n",
      "1          brief_pain_inventory_short_form_bpisf   \n",
      "\n",
      "                     Refined CRF Name  \n",
      "0  Adolescent Sleep-Wake Scale (ASWS)  \n",
      "1     Brief Pain Inventory Short Form  \n",
      "\n",
      "--- Full Response Content ---\n",
      " - CRF name: Adolescent Sleep-Wake Scale (ASWS)  \n",
      "- Rationale: The description matches the ASWS structure, focusing on adolescent self-reported sleep behaviors over the past month with frequency scales and specific domains such as going to bed, falling asleep, returning to sleep, and waking up, along with weekday and weekend sleep schedules. \n",
      "--- End of Response ---\n",
      "\n",
      "\n",
      "--- Full Response Content ---\n",
      " - CRF name: Brief Pain Inventory Short Form  \n",
      "- Rationale: The description includes key elements specific to the Brief Pain Inventory Short Form (BPI-SF), such as pain intensity ratings at worst, least, average, and current pain over the last 7 days, a body map for pain location, assessment of pain relief from treatments in the last 24 hours, and interference with general activity, mood, walking ability, work, relations, sleep, and enjoyment of life. These are hallmark features of the BPI-SF. \n",
      "--- End of Response ---\n",
      "\n",
      "Results saved to out\\SAMPLE_sprint_2020-12-16_enhanced_2025-05-29.xlsx with two sheets: 'Metadata' and 'EnhancedDD'.\n"
     ]
    }
   ],
   "source": [
    "# Main function to execute the analysis\n",
    "async def main():\n",
    "    # Step 1: Fancy Pivot Table Output\n",
    "\n",
    "    # Load the data dictionary from Excel file\n",
    "    data_dict_df = pd.read_excel(input_file, sheet_name=input_worksheet)\n",
    "    \n",
    "    # Select only the relevant columns\n",
    "    data_dict_df = data_dict_df[[crf_column, variable_column, description_column]]\n",
    "    \n",
    "    # Display the first few rows of the loaded data for confirmation\n",
    "    print(\"Loaded Data Dictionary:\")\n",
    "    print(data_dict_df.head())\n",
    "\n",
    "    # Group descriptions by each unique CRF and concatenate descriptions\n",
    "    grouped_descriptions_df = (\n",
    "        data_dict_df.groupby(crf_column)[description_column]\n",
    "        .apply(lambda x: ' '.join(x.dropna()))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Group variable names by each unique CRF and concatenate variable names\n",
    "    grouped_variables_df = (\n",
    "        data_dict_df.groupby(crf_column)[variable_column]\n",
    "        .apply(lambda x: ', '.join(x.dropna()))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Merge descriptions and variable names into one DataFrame\n",
    "    grouped_crf_df = grouped_descriptions_df.merge(\n",
    "        grouped_variables_df, on=crf_column, how='left'\n",
    "    )\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    grouped_crf_df.columns = ['CRF Name', 'Descriptions', 'Variable Names']\n",
    "    \n",
    "    # Display grouped data to verify it’s ready for analysis\n",
    "    print(\"\\nGrouped CRF Names with Descriptions and Variable Names:\")\n",
    "    print(grouped_crf_df.head())\n",
    "    \n",
    "    # Run the two-step analyze_crfs process and get the results\n",
    "    results_df = await analyze_crfs(client, grouped_crf_df)\n",
    "\n",
    "    # Step 2: Create the Enhanced Output File\n",
    "\n",
    "    # Load the input file again to ensure all original columns are included\n",
    "    full_input_df = pd.read_excel(input_file, sheet_name=input_worksheet)\n",
    "\n",
    "    # Merge the Input File with the Results File on the Original CRF Name (Form Name)\n",
    "    enhanced_output_df = full_input_df.copy()  # Start with the original input file\n",
    "    enhanced_output_df = enhanced_output_df.merge(\n",
    "        results_df[['Original CRF Name', 'Extracted CRF Name', 'Matched HEAL Core CRF', 'Match Confidence']],\n",
    "        how='left',  # Preserve all rows from the input file\n",
    "        left_on=crf_column,  # Match using the original CRF Name column from the input file\n",
    "        right_on='Original CRF Name'  # Match to the Results File column\n",
    "    )\n",
    "\n",
    "    # Optional: Reorganize the new columns to appear next to the Form Name\n",
    "    form_name_col_index = list(enhanced_output_df.columns).index(crf_column)  # Find the index of the Form Name column\n",
    "    for new_col in ['Extracted CRF Name', 'Matched HEAL Core CRF', 'Match Confidence']:\n",
    "        # Move each new column to the right of the Form Name column\n",
    "        col_data = enhanced_output_df.pop(new_col)\n",
    "        enhanced_output_df.insert(form_name_col_index + 1, new_col, col_data)\n",
    "        form_name_col_index += 1  # Adjust index for the next new column\n",
    "\n",
    "    # Save everything in a **single** Excel file with two sheets\n",
    "    output_file = config['Files']['output_file']\n",
    "    \n",
    "    with pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
    "        results_df.to_excel(writer, sheet_name=\"Metadata\", index=False)  # First sheet\n",
    "        enhanced_output_df.to_excel(writer, sheet_name=\"EnhancedDD\", index=False)  # Second sheet\n",
    "\n",
    "    print(f\"Results saved to {output_file} with two sheets: 'Metadata' and 'EnhancedDD'.\")\n",
    "\n",
    "# Run the main function in a Jupyter-compatible way\n",
    "await main()  # Place this at the end to kick off execution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
