{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4262191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ff69f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "STUDY_FILE = './out/HDP00002_HELPForNOWS_INFORMNOW_DataDictionary_REDCap.vlmd_2025-07-22.xlsx'\n",
    "STUDY_SHEET = 'EnhancedDD'\n",
    "ENCODING_COLUMN = 'enumLabels'\n",
    "FIELD_LABEL_COLUMN = 'description'\n",
    "CDE_FILE = './KnowledgeBase/Compiled_CORE_CDEs list_English_one sheet_as of 2025-01-28.xlsx'\n",
    "OUTPUT_DIR = 'out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb1e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurable thresholds\n",
    "CONFIDENCE_THRESHOLDS = {\n",
    "    'high': 80,\n",
    "    'medium': 51,\n",
    "    'minimum_score': 30  # Don't show matches below this threshold\n",
    "}\n",
    "\n",
    "# Weighting for different text components\n",
    "TEXT_WEIGHT = 0.4\n",
    "ENCODING_WEIGHT = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a0d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    \"\"\"Normalize string by converting to lowercase, handling NaN or float, and keeping spaces.\"\"\"\n",
    "    if isinstance(s, str):\n",
    "        s = re.sub(r'[^a-zA-Z0-9\\s=]', '', s.lower())  # Keep letters, numbers, spaces, and equal signs\n",
    "        s = re.sub(r'\\s+', ' ', s)  # Collapse multiple spaces into one\n",
    "        return s.strip()\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def similarity_score(str1, str2):\n",
    "    \"\"\"\n",
    "    Calculate token-based fuzzy similarity between two strings.\n",
    "    100% means an exact match, 0% means completely different.\n",
    "    \"\"\"\n",
    "    return fuzz.token_set_ratio(str1, str2)\n",
    "\n",
    "def enhanced_similarity_score(study_text, study_encoding, cde_text, cde_encoding):\n",
    "    \"\"\"\n",
    "    Enhanced similarity scoring that weights encodings and text differently.\n",
    "    Encodings are often more standardized, so they get higher weight.\n",
    "    \"\"\"\n",
    "    # Handle cases where components might be empty\n",
    "    if not study_encoding and not cde_encoding:\n",
    "        return similarity_score(study_text, cde_text)\n",
    "    if not study_text and not cde_text:\n",
    "        return similarity_score(study_encoding, cde_encoding)\n",
    "    \n",
    "    text_score = similarity_score(study_text, cde_text) if study_text and cde_text else 0\n",
    "    encoding_score = similarity_score(study_encoding, cde_encoding) if study_encoding and cde_encoding else 0\n",
    "    \n",
    "    # Weighted average\n",
    "    return (text_score * TEXT_WEIGHT) + (encoding_score * ENCODING_WEIGHT)\n",
    "\n",
    "def print_matching_summary(final_df):\n",
    "    \"\"\"Print summary statistics of the matching process.\"\"\"\n",
    "    processed_df = final_df[final_df['Best Match CDE Name'].notna()]\n",
    "    total_processed = len(processed_df)\n",
    "    \n",
    "    if total_processed == 0:\n",
    "        print(\"ðŸ“Š No matches found.\")\n",
    "        return\n",
    "    \n",
    "    high_conf = len(processed_df[processed_df['Best Match Score'] >= CONFIDENCE_THRESHOLDS['high']])\n",
    "    medium_conf = len(processed_df[\n",
    "        (processed_df['Best Match Score'] >= CONFIDENCE_THRESHOLDS['medium']) & \n",
    "        (processed_df['Best Match Score'] < CONFIDENCE_THRESHOLDS['high'])\n",
    "    ])\n",
    "    low_conf = len(processed_df[processed_df['Best Match Score'] < CONFIDENCE_THRESHOLDS['medium']])\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Matching Summary:\")\n",
    "    print(f\"   Total variables processed: {total_processed}\")\n",
    "    print(f\"   ðŸŸ¢ High confidence matches (â‰¥{CONFIDENCE_THRESHOLDS['high']}%): {high_conf} ({high_conf/total_processed*100:.1f}%)\")\n",
    "    print(f\"   ðŸŸ§ Medium confidence matches ({CONFIDENCE_THRESHOLDS['medium']}-{CONFIDENCE_THRESHOLDS['high']-1}%): {medium_conf} ({medium_conf/total_processed*100:.1f}%)\")\n",
    "    print(f\"   ðŸŸ¥ Low confidence matches (<{CONFIDENCE_THRESHOLDS['medium']}%): {low_conf} ({low_conf/total_processed*100:.1f}%)\")\n",
    "\n",
    "def compare_encodings(\n",
    "    study_file,\n",
    "    encoding_column='encodings',\n",
    "    field_label_column='field_label',\n",
    "    cde_file='./KnowledgeBase/Compiled_CORE_CDEs list_English_one sheet_as of 2025-01-28.xlsx',\n",
    "    study_sheet='Sheet1',\n",
    "    dry_run=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare study data dictionary encodings and field labels with HEAL CDE encodings using fuzzy token-based similarity.\n",
    "    \n",
    "    Parameters:\n",
    "    - study_file: Path to the study data dictionary file (.xlsx or .csv).\n",
    "    - encoding_column: Name of the column containing encodings in the study file.\n",
    "    - field_label_column: Name of the column containing field labels in the study file.\n",
    "    - cde_file: Path to the HEAL CDE knowledge base file (.xlsx).\n",
    "    - study_sheet: Name of the sheet in the study file to process (default is 'Sheet1').\n",
    "    - dry_run: If True, only preview the process without actually running matches.\n",
    "    \n",
    "    Returns:\n",
    "    - str: Path to the output file with CDE matches.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Load study data\n",
    "    print(\"ðŸ“‚ Loading study data...\")\n",
    "    if study_file.endswith('.xlsx'):\n",
    "        full_study_df = pd.read_excel(study_file, sheet_name=study_sheet)\n",
    "    else:\n",
    "        full_study_df = pd.read_csv(study_file)\n",
    "\n",
    "    # Filter out 'No CRF match rows' - only process rows that have confirmed CRF matches\n",
    "    if 'HEAL Core CRF Match' in full_study_df.columns:\n",
    "        skipped_df = full_study_df[full_study_df['HEAL Core CRF Match'] == 'No CRF match'].copy()\n",
    "        study_df = full_study_df[full_study_df['HEAL Core CRF Match'] != 'No CRF match'].copy()\n",
    "        print(f\"âœ… Processing {len(study_df)} rows; skipping {len(skipped_df)} rows (No CRF match).\")\n",
    "    else:\n",
    "        skipped_df = pd.DataFrame()\n",
    "        study_df = full_study_df.copy()\n",
    "        print(f\"âœ… Processing all {len(study_df)} rows (no CRF match column found).\")\n",
    "\n",
    "    if dry_run:\n",
    "        print(f\"ðŸ” DRY RUN: Would process {len(study_df)} variables against HEAL CDEs\")\n",
    "        return None\n",
    "\n",
    "    # Initialize new columns for CDE matches\n",
    "    new_cols = [\n",
    "        'Best Match CDE Name', 'Best Match Score', 'Best Match CRF Name',\n",
    "        'Potential Match 2 - CDE Name', 'Potential Match 2 - Score', 'Potential Match 2 - CRF Name',\n",
    "        'Potential Match 3 - CDE Name', 'Potential Match 3 - Score', 'Potential Match 3 - CRF Name'\n",
    "    ]\n",
    "    for col in new_cols:\n",
    "        study_df[col] = None\n",
    "    \n",
    "    # Normalize study encodings and field labels for comparison\n",
    "    print(\"ðŸ”§ Normalizing study variables...\")\n",
    "    study_df['Normalized Text'] = study_df[field_label_column].apply(normalize_string)\n",
    "    study_df['Normalized Encoding'] = study_df[encoding_column].apply(normalize_string)\n",
    "    study_df['Normalized Combined'] = study_df.apply(\n",
    "        lambda row: normalize_string(str(row[encoding_column]) + \" | \" + str(row[field_label_column]))\n",
    "        if pd.notna(row[encoding_column]) and pd.notna(row[field_label_column]) else '',\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Load and normalize HEAL CDE encodings\n",
    "    print(\"ðŸ“š Loading HEAL CDE database...\")\n",
    "    cde_df = pd.read_excel(cde_file, sheet_name='ALL')\n",
    "    cde_df = cde_df.dropna(subset=['PV Description', 'Additional Notes (Question Text)'])\n",
    "    \n",
    "    # Normalize CDE components separately for enhanced matching\n",
    "    cde_df['Normalized Text'] = cde_df['Additional Notes (Question Text)'].apply(normalize_string)\n",
    "    cde_df['Normalized Encoding'] = cde_df['PV Description'].apply(normalize_string)\n",
    "    cde_df['Normalized Combined'] = (\n",
    "        cde_df['Additional Notes (Question Text)'].fillna('') + \" | \" + cde_df['PV Description'].fillna('')\n",
    "    ).apply(normalize_string)\n",
    "    \n",
    "    print(f\"âœ… Loaded {len(cde_df)} HEAL CDEs for comparison.\")\n",
    "    \n",
    "    # Track low-confidence matches for analysis\n",
    "    low_confidence_matches = []\n",
    "    \n",
    "    # Run comparisons only on filtered rows (those with confirmed CRF matches)\n",
    "    print(\"ðŸ” Running enhanced fuzzy matching against HEAL CDEs...\")\n",
    "    \n",
    "    for idx, row in tqdm(study_df.iterrows(), total=len(study_df), desc=\"Matching variables\", unit=\"vars\"):\n",
    "        if row['Normalized Combined'] == '':\n",
    "            continue\n",
    "\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        best_crf_name = None\n",
    "        potential_matches = []\n",
    "\n",
    "        # Compare against all HEAL CDEs using enhanced scoring\n",
    "        for _, cde_row in cde_df.iterrows():\n",
    "            # Use enhanced similarity that weights text and encodings differently\n",
    "            score_percentage = enhanced_similarity_score(\n",
    "                row['Normalized Text'], \n",
    "                row['Normalized Encoding'],\n",
    "                cde_row['Normalized Text'], \n",
    "                cde_row['Normalized Encoding']\n",
    "            )\n",
    "            \n",
    "            # Only consider matches above minimum threshold\n",
    "            if score_percentage >= CONFIDENCE_THRESHOLDS['minimum_score']:\n",
    "                if score_percentage > best_score:\n",
    "                    best_match = cde_row['Variable Name']\n",
    "                    best_score = score_percentage\n",
    "                    best_crf_name = cde_row['CRF Name']\n",
    "                potential_matches.append((cde_row['Variable Name'], score_percentage, cde_row['CRF Name']))\n",
    "\n",
    "        # Sort potential matches by score and remove duplicates\n",
    "        potential_matches.sort(key=lambda x: x[1], reverse=True)\n",
    "        unique_matches, seen = [], set()\n",
    "        for name, score, crf in potential_matches:\n",
    "            if name not in seen:\n",
    "                unique_matches.append((name, score, crf))\n",
    "                seen.add(name)\n",
    "        if best_match:\n",
    "            unique_matches = [m for m in unique_matches if m[0] != best_match]\n",
    "\n",
    "        # Save best match and top 2 alternatives\n",
    "        if best_match:\n",
    "            study_df.at[idx, 'Best Match CDE Name'] = best_match\n",
    "            study_df.at[idx, 'Best Match Score'] = round(best_score, 1)\n",
    "            study_df.at[idx, 'Best Match CRF Name'] = best_crf_name\n",
    "            \n",
    "            # Track low-confidence matches for analysis\n",
    "            if best_score < CONFIDENCE_THRESHOLDS['high']:\n",
    "                low_confidence_matches.append({\n",
    "                    'Row': idx + 2,  # Excel row number\n",
    "                    'Study_Variable': row.get('field_name', 'Unknown'),\n",
    "                    'Study_Text': row['Normalized Combined'][:100] + '...' if len(row['Normalized Combined']) > 100 else row['Normalized Combined'],\n",
    "                    'Best_CDE': best_match,\n",
    "                    'Score': round(best_score, 1),\n",
    "                    'CRF_Name': best_crf_name\n",
    "                })\n",
    "                \n",
    "        for i, (match_name, match_score, crf_name) in enumerate(unique_matches[:2], start=2):\n",
    "            study_df.at[idx, f'Potential Match {i} - CDE Name'] = match_name\n",
    "            study_df.at[idx, f'Potential Match {i} - Score'] = round(match_score, 1)\n",
    "            study_df.at[idx, f'Potential Match {i} - CRF Name'] = crf_name\n",
    "\n",
    "    # Create low-confidence matches DataFrame for analysis\n",
    "    low_conf_df = pd.DataFrame(low_confidence_matches) if low_confidence_matches else pd.DataFrame()\n",
    "\n",
    "    # Merge skipped rows back with empty match columns\n",
    "    for col in new_cols:\n",
    "        if col not in skipped_df.columns:\n",
    "            skipped_df[col] = None\n",
    "    if 'Normalized Combined' not in skipped_df.columns:\n",
    "        skipped_df['Normalized Combined'] = None\n",
    "\n",
    "    final_df = pd.concat([study_df, skipped_df], ignore_index=True)\n",
    "\n",
    "    # Save results with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_base = os.path.basename(study_file).rsplit('.', 1)[0]\n",
    "    output_file = f\"{OUTPUT_DIR}/{output_base}_vlmd_cdesearch_{timestamp}.xlsx\"\n",
    "    \n",
    "    # Write multiple sheets\n",
    "    with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "        final_df.to_excel(writer, sheet_name='VLMD_Results', index=False)\n",
    "        \n",
    "        if not low_conf_df.empty:\n",
    "            low_conf_df.to_excel(writer, sheet_name='Low_Confidence_Analysis', index=False)\n",
    "            print(f\"ðŸ“ {len(low_conf_df)} low-confidence matches saved for analysis\")\n",
    "    \n",
    "    print(f\"ðŸ’¾ CDE matching complete. Results saved to {output_file}\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print_matching_summary(final_df)\n",
    "\n",
    "    return output_file\n",
    "\n",
    "def apply_color_coding(output_file):\n",
    "    \"\"\"\n",
    "    Apply color coding to the Excel file based on confidence levels:\n",
    "    - Green (â‰¥80): High confidence\n",
    "    - Orange (51-79): Medium confidence  \n",
    "    - Red (â‰¤50): Low confidence\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸŽ¨ Applying color coding and confidence levels...\")\n",
    "    \n",
    "    wb = load_workbook(output_file)\n",
    "    \n",
    "    # Work with the main results sheet\n",
    "    ws = wb['VLMD_Results'] if 'VLMD_Results' in wb.sheetnames else wb.active\n",
    "\n",
    "    # Find \"Best Match Score\" column\n",
    "    best_match_score_col = None\n",
    "    for idx, cell in enumerate(ws[1], start=1):\n",
    "        if cell.value == \"Best Match Score\":\n",
    "            best_match_score_col = idx\n",
    "            break\n",
    "\n",
    "    if best_match_score_col:\n",
    "        # Insert Confidence Level column\n",
    "        confidence_col_idx = best_match_score_col + 1\n",
    "        ws.insert_cols(confidence_col_idx)\n",
    "        ws.cell(row=1, column=confidence_col_idx).value = \"Confidence Level\"\n",
    "\n",
    "        # Apply color coding and confidence levels\n",
    "        for row_idx, row in enumerate(ws.iter_rows(min_row=2, min_col=best_match_score_col, max_col=best_match_score_col), start=2):\n",
    "            for cell in row:\n",
    "                score = cell.value\n",
    "                confidence_cell = ws.cell(row=row_idx, column=confidence_col_idx)\n",
    "                if score is not None:\n",
    "                    if score >= CONFIDENCE_THRESHOLDS['high']:\n",
    "                        confidence_cell.value = \"High confidence\"\n",
    "                        cell.fill = PatternFill(start_color=\"C6EFCE\", end_color=\"C6EFCE\", fill_type=\"solid\")  # Green\n",
    "                    elif CONFIDENCE_THRESHOLDS['medium'] <= score < CONFIDENCE_THRESHOLDS['high']:\n",
    "                        confidence_cell.value = \"Medium confidence\"\n",
    "                        cell.fill = PatternFill(start_color=\"FFEB9C\", end_color=\"FFEB9C\", fill_type=\"solid\")  # Orange\n",
    "                    else:\n",
    "                        confidence_cell.value = \"Low confidence\"\n",
    "                        cell.fill = PatternFill(start_color=\"FFC7CE\", end_color=\"FFC7CE\", fill_type=\"solid\")  # Red\n",
    "\n",
    "    wb.save(output_file)\n",
    "    print(f\"âœ¨ Color coding and confidence levels applied!\")\n",
    "\n",
    "def main(dry_run=False):\n",
    "    \"\"\"Main function to run the VLMD CDE matching process.\"\"\"\n",
    "    \n",
    "    print(\"ðŸš€ Starting HEAL CDE Variable Level Metadata Matching\")\n",
    "    print(f\"ðŸ“‹ Configuration: High confidence â‰¥{CONFIDENCE_THRESHOLDS['high']}%, Medium â‰¥{CONFIDENCE_THRESHOLDS['medium']}%, Minimum threshold â‰¥{CONFIDENCE_THRESHOLDS['minimum_score']}%\")\n",
    "    \n",
    "    # Run CDE matching\n",
    "    output_file = compare_encodings(\n",
    "        STUDY_FILE,\n",
    "        encoding_column=ENCODING_COLUMN,\n",
    "        field_label_column=FIELD_LABEL_COLUMN,\n",
    "        study_sheet=STUDY_SHEET,\n",
    "        cde_file=CDE_FILE,\n",
    "        dry_run=dry_run\n",
    "    )\n",
    "\n",
    "    if not dry_run and output_file:\n",
    "        # Apply color coding for easier review\n",
    "        apply_color_coding(output_file)\n",
    "        \n",
    "        print(f\"\\nðŸŽ‰ VLMD CDE matching complete!\")\n",
    "        print(f\"ðŸ“Š Results saved to: {output_file}\")\n",
    "        print(f\"ðŸ“‹ Review the 'Low_Confidence_Analysis' sheet to improve future matching\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set dry_run=True to preview without processing\n",
    "    main(dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27000ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92bdd33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bfc801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5261417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf4da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cd8d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e36c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dcf7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16c13678",
   "metadata": {},
   "source": [
    "# HEAL CDE Fuzzy Matching Script\n",
    "\n",
    "This script automates the matching of study data dictionaries to the HEAL Core Common Data Elements (CDEs), using smart fuzzy text comparison and a color-coded Excel output for easier review.\n",
    "\n",
    "It is designed to help identify the **Best Match** and **Top 2 Potential Matches** for each study variable â€” even if the wording or encoding order is slightly different from the CDE standard.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ¨ Key Features\n",
    "- **Fuzzy Matching**: Uses token-based similarity (`Token Set Ratio`) to handle small typos and different word orders.\n",
    "- **Normalized Comparisons**: Cleans and standardizes text for reliable matching.\n",
    "- **Separate Output Folder**: All results are saved neatly into an `/out/` subfolder.\n",
    "- **Color Coded Scores**:  \n",
    "  - ðŸŸ© **Green** for matches â‰¥ 80%  \n",
    "  - ðŸŸ§ **Orange** for matches 51â€“79%  \n",
    "  - ðŸŸ¥ **Red** for matches â‰¤ 50%\n",
    "- **No Duplicate Matches**: Ensures Best Match and Potential Matches are truly different.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ How It Works\n",
    "\n",
    "1. **Input**:\n",
    "   - A study data dictionary (Excel `.xlsx` or CSV `.csv` file).\n",
    "   - The master HEAL CDEs file (Excel file).\n",
    "\n",
    "2. **Process**:\n",
    "   - Normalize (clean) text by lowercasing, removing special characters, and preserving logical structures like equal signs.\n",
    "   - Compare the study's \"Encoding + Field Label\" to the CDE's \"PV Description + Question Text\".\n",
    "   - Select the best match and top two alternatives based on fuzzy matching scores.\n",
    "   - Color-code the best match scores for easy visualization.\n",
    "\n",
    "3. **Output**:\n",
    "   - A new Excel file saved into `/out/`, with best matches listed and scores color-coded.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ› ï¸ Requirements\n",
    "\n",
    "Install the following Python packages:\n",
    "\n",
    "```bash\n",
    "pip install pandas openpyxl fuzzywuzzy\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‚ Folder Structure\n",
    "\n",
    "```\n",
    "/in/         # Input study files\n",
    "/out/        # Output matched files (automatically created if not present)\n",
    "/KnowledgeBase/ # Contains the HEAL Core CDE file\n",
    "script.py    # Your main script\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Usage Example\n",
    "\n",
    "```bash\n",
    "python script.py\n",
    "```\n",
    "\n",
    "The output file will appear in the `/out/` folder and will be named something like:\n",
    "\n",
    "```\n",
    "SAMPLE_sprint_2020-12-16_vlmd_cdesearch.xlsx\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Notes\n",
    "\n",
    "- The script **requires** the correct columns to be named in the study file (e.g., `Choices, Calculations, OR Slider Labels` and `Field Label`).\n",
    "- Only the **Best Match Score** column is color coded for quick review.\n",
    "- Ensure your HEAL CDE master file contains the necessary columns: `PV Description` and `Additional Notes (Question Text)`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
